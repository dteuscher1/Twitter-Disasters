---
title: "Disaster Tweets: NLP Approaches"
output: html_document
---

<!--
TO DO:
* Use custom features and tdf for classification
* Create ensemble for multiple methods
** Create bagging ensemble (one model at a time)
** See https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/
* TDF: remove stop-words
* Play with model parameters
-->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(stringr)
library(sentimentr)
library(tidyverse)
library(caret)
library(text2vec)
library(glmnet)
```

# Preprocessing

## Feature Engineering

To begin with, we created variables to represent any useful patterns found within texts that may indicate whether a given tweet is about a real disaster.

```{r}
custom_features <- function(twitter) {
  # Wrapper for all custom variables
  # Useful for adding custom features for train and test sets separately
  # Args:
  #   twitter: data.frame with twitter dataset from Kaggle nlp challenge
  # Returns:
  #   original twitter dataset including custom variable columns
  
  twitter <- twitter %>%
    mutate(url_count = str_count(text, "http[\\S]+"),
           text = str_replace_all(text, "http[\\S]+", "http"), # remove URLs
           punct_count = str_count(text, "[.!?,\"'-]"),
           handles_count = str_count(text, "[@]"),
           hashtag_count = str_count(twitter$text, "[#]"),
           char_count = nchar(twitter$text), # tweet length
           capital_count = str_count(twitter$text, "[A-Z]"),
           capital_prop = capital_count/char_count,
           number_count = str_count(twitter$text, "[0-9]")
           )
  
  # Add message tone variable
  sentiment_df <- sentiment_by(get_sentences(twitter$text))
  twitter$tone <- sentiment_df$ave_sentiment
  
  # Add word count
  twitter$word <- sentiment_df$word_count
  
  return(twitter)
}
```

```{r, message=FALSE}
# Read in training data
twitter <- read_csv("train.csv")
twitter_test <- read_csv('test.csv')

twitter <- custom_features(twitter)
twitter_test <- custom_features(twitter_test)
```

## Converting Text to Usable Predictors (Term Document Frequency)

```{r}
text2vec_iterator <- function(twitter) {
  # Args:
  #   twitter: data.frame with twitter dataset from Kaggle nlp challenge
  # Returns:
  #   iterator object to create a vocabulary and vector space 
  
  prep_fun <- tolower
  tok_fun <- word_tokenizer
  iterator <- itoken(twitter$text,
                       preprocessor = tolower,
                       tokenizer = word_tokenizer,
                       ids = twitter$id,
                       progressbar = TRUE)
  return(iterator)
}
```

```{r}
set.seed(2020)

# use twit.1 to create vector space with words from entire corpus
twit.1 <- tibble(id = c(twitter$id, twitter_test$id),
                 text = c(twitter$text, twitter_test$text))

twit_train <- text2vec_iterator(twit.1)
vocab <- create_vocabulary(twit_train)

# Create vector space for given vocabulary set
vectorizer <- vocab_vectorizer(vocab)

# Create document-term matrix for training data
twit_train <- text2vec_iterator(twitter)
dtm_train <- create_dtm(twit_train, vectorizer)

# ...for test data
twit_test <- text2vec_iterator(twitter_test)
dtm_test <- create_dtm(twit_test, vectorizer)
```

## Combine Custom and Term-Document-Frequency Variables

```{r}
allvars_train <- twitter %>%
  select(-c(id:target)) %>%
  as.matrix() %>%
  cbind(dtm_train)
allvars_test <- twitter_test %>%
  select(-c(id:text)) %>%
  as.matrix() %>%
  cbind(dtm_test)
```

# Modeling

## Logistic Regression
<!--This is as far as I have gotten so far with merging files (Skyler)-->

```{r}
glmnet.classifier.log <- cv.glmnet(x = dtm_train,
                                   y = as.factor(twitter$target),
                                   family = "binomial",
                                   alpha = 1, 
                                   type.measure = "auc",
                                   nfolds = 4, 
                                   thresh = 1e-3,
                                   maxit = 1e3)
plot(glmnet.classifier.log)
print(paste("max AUC =", round(max(glmnet.classifier.log$cvm), 4)))

twit_test <- twitter_test$text %>% prep_fun %>% tok_fun %>% itoken(., ids = twitter_test$id)
dtm_test <- create_dtm(twit_test, vectorizer)

# preds.log.2 <- predict(glmnet.classifier.log, dtm_test, type = "class")[,1]
preds.log <- predict(glmnet.classifier.log, dtm_test, type = "response")[,1]

preds.log.out2 <- cbind("id" = twitter_test$id, as.integer(preds.log > 0.45))
write_csv(as.data.frame(preds.log.out2), 'preds.log.out2.csv')


#cross validation
set.seed(2020)
test.set <- sample( 1:nrow(twitter), 0.1*nrow(twitter))
twit.train <- twitter[-test.set,]
twit.test <- twitter[test.set,]

cv_train <- itoken(twit.train$text,
                     preprocessor = tolower,
                     tokenizer = word_tokenizer,
                     ids = twit.train$id,
                     progressbar = TRUE)
vocab <- create_vocabulary(cv_train)
vectorizer <- vocab_vectorizer(vocab) 
dtm_train <- create_dtm(cv_train, vectorizer) #creating document text matrix
glmnet.classifier.cv <- cv.glmnet(x = dtm_train,
                                   y = as.factor(twit.train$target),
                                   family = "binomial",
                                   alpha = 1, 
                                   type.measure = "auc",
                                   nfolds = 4, 
                                   thresh = 1e-3,
                                   maxit = 1e3)
cv_test <- twit.test$text %>% prep_fun %>% tok_fun %>% itoken(., ids = twit.test$id)
dtm_test <- create_dtm(cv_test, vectorizer)

cv.perc <- c()
for (i in seq(.3, .7, by = 0.01)) {
  print(i)
  cv.perc <- append(cv.perc, mean((as.integer(as.numeric(predict(glmnet.classifier.cv, dtm_test, type = "response")[,1]) > i))  == twit.test$target))
  
}
seq(.3, .7, by = 0.01)[which.max(cv.perc)]


mean(preds.log.out[,2] == submission_word2vec[,2])
write_csv(as.data.frame(preds.log.out), 'preds.log.out.csv')



preds.log.out <- cbind("id" = twitter_test$id, as.integer(preds.log > 0.45))


## Adjustments
twit_train <- itoken(twitter$text, #<- change to twit.1 if using test data set to create vector space
                     preprocessor = tolower,
                     tokenizer = word_tokenizer,
                     ids = twitter$id,
                     progressbar = TRUE)
vocab <- create_vocabulary(twit_train, stopwords = stopwords_en)
pruned_vocab <- prune_vocabulary(vocab, 
                                term_count_min = 10, 
                                doc_proportion_max = 0.5,
                                doc_proportion_min = 0.001)
vectorizer <- vocab_vectorizer(pruned_vocab) 

dtm_train  <- create_dtm(twit_train, vectorizer)
dim(dtm_train)
glmnet_classifier <- cv.glmnet(x = dtm_train, y = twitter$target, 
                              family = 'binomial', 
                              alpha = 1,
                              type.measure = "auc",
                              nfolds = 10,
                              thresh = 1e-3,
                              maxit = 1e3)
print(paste("max AUC =", round(max(glmnet_classifier$cvm), 4)))

# Adding additional variables
#1 Punctuation - .!?,"'-
twitter$url_count <- str_count(twitter$text, "http(.*)$")

# Removed urls
twitter$text <- gsub("http(.*)$", "http", twitter$text)

twitter$punct_count <- str_count(twitter$text, "[.!?,\"'-]" )

#2 Handles - @
twitter$handles_count <- str_count(twitter$text, "[@]" )

#3 Hashtag - #
twitter$hashtag_count <- str_count(twitter$text, "[#]" )

#4 Length
twitter$characters <- nchar(twitter$text)

# Capital letter
twitter$capital <- str_count(twitter$text, "[A-Z]")

# Numbers
twitter$numbers <- str_count(twitter$text, "[0-9]")

# Tone
sentiment_df <- sentiment_by(get_sentences(twitter$text))

twitter$tone <- sentiment_df$ave_sentiment

# Word count
twitter$word <- sentiment_df$word_count

# Proportion of capital to lower case letters
twitter <- twitter %>% mutate("cap.prop" = capital/characters)

add.variables <- twitter %>% select(6:15) %>% as.matrix()
mat.variables <- cbind(dtm_train, add.variables)

glmnet_classifier1 <- cv.glmnet(x = mat.variables, y = twitter$target, 
                               family = 'binomial', 
                               alpha = 1,
                               type.measure = "auc",
                               nfolds = 10,
                               thresh = 1e-3,
                               maxit = 1e3)
plot(glmnet_classifier1)
print(paste("max AUC =", round(max(glmnet_classifier1$cvm), 4)))
print(paste("max AUC =", round(max(glmnet_classifier$cvm), 4)))

vocab1 <- create_vocabulary(twit_train, ngram = c(1L, 2L))
vocab1 <- prune_vocabulary(vocab1, term_count_min = 10, 
                         doc_proportion_max = 0.5)
bigram_vectorizer <- vocab_vectorizer(vocab1)
dtm_train <- create_dtm(twit_train, bigram_vectorizer)
glmnet_classifier2 <- cv.glmnet(x = dtm_train, y = twitter$target, 
                              family = 'binomial', 
                              alpha = 1,
                              type.measure = "auc",
                              nfolds = 10,
                              thresh = 1e-3,
                              maxit = 1e3)
plot(glmnet_classifier2)
print(paste("max AUC =", round(max(glmnet_classifier1$cvm), 4)))
print(paste("max AUC =", round(max(glmnet_classifier$cvm), 4)))
print(paste("max AUC =", round(max(glmnet_classifier2$cvm), 4)))
```

# Support Vector Machine
<!--NEED TO VERIFY IT WORKS AND PERFORMANCE-->

```{r}
# filling missing values
twitter$keyword[is.na(twitter$keyword)] <- "None"
twitter$location[is.na(twitter$location)] <- "None"

# Making the target variable a factor
twitter %>% mutate(target = if_else(target=='1', 'Y', 'N'))

# Re-ordering columns. Unsure if necessary
twitter <- twitter[, c(1:4, 6:12, 5)]

svmFit <- train(target ~ . -id -text, 
                data = twitter, 
                method = "svmRadial", 
                trControl = fitControl, 
                preProc = c("center", "scale"),
                tuneLength = 4,
                metric = "ROC")
svmFit 
```

# Naive Bayes
<!--NEED TO VERIFY IT WORKS AND PERFORMANCE-->

```{r}
# Add indicator variables for keyword and location
twitter1 <- twitter %>%
  mutate(target = factor(ifelse(target == 1, "Yes", "No"), levels = c("No", "Yes")),
         keyword_ind = ifelse(is.na(keyword), 0, 1),
         location_ind = ifelse(is.na(location), 0, 1))

# Create data frame of predictor variables
x <- twitter1 %>% select(-id, -text, -target, -keyword, -location) %>% as.data.frame()
# Create vector of the response variable
y <- twitter1$target

# Specifies the type of cross validation and to return AUC, sensitivity, and specificity
myControl <- trainControl(
  method="cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary
)

# Creates a grid to test different values of hyperparameters
grid <- expand.grid(laplace=seq(0,10, length = 5), usekernel=c(TRUE,FALSE), adjust=seq(1,10, length = 5))

# Fit of the Naive Bayes model
nb.model <- train(
  x=x,
  y=y,
  method = "naive_bayes",
  trControl = myControl,
  tuneGrid = grid,
  metric="ROC"
)

nb.model
summary(nb.model)

# Show a plot comparing the models with different hyperparameter values
plot(nb.model)
```

# Random Forest
<!--NEED TO VERIFY IT WORKS AND PERFORMANCE-->

```{r}
library(randomForest)

# Indicator for non-NA locations and keywords
twitter$keywordInd <- !is.na(twitter$keyword)
twitter$locationIng <- !is.na(twitter$location)

# I didn't use the first few columns (id, keyword, location, text)
twitter.clean <- twitter[,-c(1:4)]
twitter.clean$target <- as.factor(twitter.clean$target)

# Subsetting to creating training and testing sets
twitter.sub <- sample(nrow(twitter), round(0.9*nrow(twitter)))
twitter.train.use <- twitter.clean[twitter.sub,]
twitter.train.test <- twitter.clean[-twitter.sub,]

# Random Forest Model
twitter.rf <- randomForest(target~.,
                           data=twitter.train.use,
                           mtry=5,
                           ntree=800,
                           importance=TRUE)

# RF plots we did with Heaton, but I forgot what they mean lol
plot(twitter.rf)
varImpPlot(twitter.rf)

# Prediction Assessment (I got around .72)
twitter.train.test$predict <- predict(twitter.rf, newdata=twitter.train.test)
sum(twitter.train.test$target == twitter.train.test$predict) / nrow(twitter.train.test)
```

